name: Kafka Async Polling E2E Tests

on:
  pull_request:
    paths:
      - 'bizon/connectors/sources/kafka/**'
      - 'tests/e2e/test_e2e_kafka_async_polling.py'
      - 'tests/connectors/sources/kafka/**'
      - '.github/workflows/kafka-e2e.yml'
  push:
    branches:
      - main
      - develop
    paths:
      - 'bizon/connectors/sources/kafka/**'
      - 'tests/e2e/test_e2e_kafka_async_polling.py'
      - 'tests/connectors/sources/kafka/**'
  workflow_dispatch: # Allow manual trigger

permissions:
  contents: read

jobs:
  kafka-e2e-test:
    name: Kafka Async Polling E2E Tests
    runs-on: ubuntu-latest
    timeout-minutes: 15


    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python 3.10
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Start Redpanda
      run: |
        echo "Starting Redpanda container..."
        docker run -d \
          --name redpanda \
          -p 9092:9092 \
          -p 9644:9644 \
          docker.redpanda.com/redpandadata/redpanda:latest \
          redpanda start \
          --node-id 0 \
          --mode dev-container \
          --kafka-addr internal://0.0.0.0:9092,external://0.0.0.0:19092 \
          --advertise-kafka-addr internal://redpanda:9092,external://localhost:9092 \
          --pandaproxy-addr internal://0.0.0.0:8082,external://0.0.0.0:18082 \
          --advertise-pandaproxy-addr internal://redpanda:8082,external://localhost:8082 \
          --schema-registry-addr internal://0.0.0.0:8081,external://0.0.0.0:18081 \
          --rpc-addr redpanda:33145 \
          --advertise-rpc-addr redpanda:33145 \
          --smp 1 \
          --memory 1G \
          --reserve-memory 0M \
          --overprovisioned \
          --set redpanda.empty_seed_starts_cluster=false \
          --set redpanda.auto_create_topics_enabled=true

    - name: Wait for Redpanda to be ready
      run: |
        echo "Waiting for Redpanda to be ready..."
        timeout 60s bash -c 'until docker exec redpanda rpk cluster info; do sleep 2; done'
        echo "Redpanda is ready!"

    - name: Install Poetry
      uses: snok/install-poetry@v1
      with:
        version: latest
        virtualenvs-create: true
        virtualenvs-in-project: true

    - name: Load cached venv
      id: cached-poetry-dependencies
      uses: actions/cache@v3
      with:
        path: .venv
        key: venv-${{ runner.os }}-${{ steps.setup-python.outputs.python-version }}-${{ hashFiles('**/poetry.lock') }}

    - name: Install dependencies
      if: steps.cached-poetry-dependencies.outputs.cache-hit != 'true'
      run: poetry install --with test --all-extras

    - name: Verify Redpanda connection
      run: |
        echo "Verifying Redpanda (Kafka-compatible) setup..."
        poetry run python -c "
        from confluent_kafka import Producer
        import time
        
        producer = Producer({'bootstrap.servers': 'localhost:9092'})
        producer.produce('test-topic', 'test-message')
        producer.flush()
        print('âœ… Redpanda connection verified!')
        "

    - name: Create test topics and produce data
      run: |
        poetry run python -c "
        import json
        import time
        from confluent_kafka import Producer
        from confluent_kafka.admin import AdminClient, NewTopic
        
        print('ğŸ¯ Setting up Redpanda test environment...')
        
        # Create topics
        admin_client = AdminClient({'bootstrap.servers': 'localhost:9092'})
        topics = [
            NewTopic('async-test-high-volume', num_partitions=3, replication_factor=1),
            NewTopic('async-test-low-volume', num_partitions=1, replication_factor=1)
        ]
        
        futures = admin_client.create_topics(topics)
        for topic_name, future in futures.items():
            try:
                future.result(timeout=10)
                print(f'âœ… Created topic: {topic_name}')
            except Exception as e:
                if 'already exists' in str(e).lower():
                    print(f'â„¹ï¸  Topic {topic_name} already exists')
                else:
                    print(f'âŒ Failed to create topic {topic_name}: {e}')
                    raise
        
        # Produce test data
        producer = Producer({
            'bootstrap.servers': 'localhost:9092',
            'client.id': 'ci-test-producer'
        })
        
        print('ğŸš€ Producing test data to simulate starvation scenario...')
        
        # High-volume topic - simulate heavy load (200 messages)
        for i in range(200):
            message = {
                'id': f'high-vol-{i}',
                'type': 'high_volume',
                'data': f'High volume message {i}',
                'timestamp': int(time.time() * 1000),
                'batch': i // 20
            }
            
            producer.produce(
                'async-test-high-volume',
                key=f'high-vol-{i}',
                value=json.dumps(message),
                partition=i % 3
            )
            
            if i % 50 == 0:
                producer.flush()
        
        # Low-volume topic - simulate critical but infrequent messages (10 messages)
        for i in range(10):
            message = {
                'id': f'low-vol-{i}',
                'type': 'low_volume',
                'data': f'Critical message {i}',
                'priority': 'HIGH',
                'timestamp': int(time.time() * 1000),
                'sequence': i
            }
            
            producer.produce(
                'async-test-low-volume',
                key=f'low-vol-{i}',
                value=json.dumps(message),
                partition=0
            )
        
        producer.flush()
        print('ğŸ“¦ Test data produced successfully!')
        print('   - High-volume topic: 200 messages across 3 partitions')
        print('   - Low-volume topic: 10 critical messages in 1 partition')
        "

    - name: Run Kafka async polling unit tests
      run: |
        echo "ğŸ§ª Running async polling unit tests..."
        poetry run pytest tests/connectors/sources/kafka/test_async_polling.py -v --tb=short

    - name: Run Kafka async polling integration test
      run: |
        echo "ğŸ”¬ Running async polling integration test..."
        poetry run python -c "
        import json
        import tempfile
        import os
        from pathlib import Path
        
        # Create test output directory
        test_output_dir = tempfile.mkdtemp(prefix='kafka_async_test_')
        print(f'ğŸ“ Test output directory: {test_output_dir}')
        
        # Test configuration
        config_yaml = '''
        name: ci_kafka_async_polling_test
        source:
          name: kafka
          stream: topic
          sync_mode: stream
          topics:
            - name: async-test-high-volume
              destination_id: high_volume
            - name: async-test-low-volume
              destination_id: low_volume
          bootstrap_servers: localhost:9092
          group_id: ci-async-test-group
          batch_size: 30
          consumer_timeout: 2
          enable_async_polling: true
          poll_interval_ms: 50
          max_poll_records: 100
          partition_pause_threshold: 500
          message_encoding: utf-8
          max_iterations: 8
          authentication:
            type: basic
            params:
              username: test
              password: test
            schema_registry_type: apicurio
            schema_registry_url: ''
            schema_registry_username: ''
            schema_registry_password: ''
        destination:
          name: file
          config:
            output_dir: ''' + test_output_dir + '''
            record_schemas:
              - destination_id: high_volume
                record_schema:
                  - name: id
                    type: string
                    nullable: false
                  - name: type
                    type: string
                    nullable: false
                  - name: data
                    type: string
                    nullable: false
                  - name: timestamp
                    type: integer
                    nullable: false
              - destination_id: low_volume
                record_schema:
                  - name: id
                    type: string
                    nullable: false
                  - name: type
                    type: string
                    nullable: false
                  - name: data
                    type: string
                    nullable: false
                  - name: priority
                    type: string
                    nullable: false
                  - name: timestamp
                    type: integer
                    nullable: false
        engine:
          runner:
            type: stream
          backend:
            type: sqlite
            config:
              database_path: ''' + os.path.join(test_output_dir, 'test.db') + '''
        '''
        
        # Write config to file
        config_file = os.path.join(test_output_dir, 'config.yml')
        with open(config_file, 'w') as f:
            f.write(config_yaml)
        
        print(f'ğŸ“„ Config written to: {config_file}')
        
        # Set environment for production mode (enables commits)
        os.environ['ENVIRONMENT'] = 'production'
        
        # Run bizon
        print('ğŸš€ Running bizon with async polling...')
        
        import yaml
        from bizon.engine.engine import RunnerFactory
        
        with open(config_file, 'r') as f:
            config_dict = yaml.safe_load(f)
        
        runner = RunnerFactory.create_from_config_dict(config_dict)
        result = runner.run()
        
        print(f'âœ… Bizon completed with status: {result}')
        
        # Analyze results
        print('ğŸ“Š Analyzing consumption results...')
        
        high_vol_file = os.path.join(test_output_dir, 'high_volume.json')
        low_vol_file = os.path.join(test_output_dir, 'low_volume.json')
        
        high_vol_count = 0
        low_vol_count = 0
        
        if os.path.exists(high_vol_file):
            with open(high_vol_file, 'r') as f:
                high_vol_count = sum(1 for line in f if line.strip())
        
        if os.path.exists(low_vol_file):
            with open(low_vol_file, 'r') as f:
                low_vol_count = sum(1 for line in f if line.strip())
        
        total_consumed = high_vol_count + low_vol_count
        
        print(f'ğŸ“ˆ Consumption Results:')
        print(f'   High-volume messages: {high_vol_count}')
        print(f'   Low-volume messages:  {low_vol_count}')
        print(f'   Total consumed:       {total_consumed}')
        
        if total_consumed > 0:
            high_vol_pct = (high_vol_count / total_consumed) * 100
            low_vol_pct = (low_vol_count / total_consumed) * 100
            
            print(f'ğŸ“Š Fairness Analysis:')
            print(f'   High-volume: {high_vol_pct:.1f}%')
            print(f'   Low-volume:  {low_vol_pct:.1f}%')
        
        # Assertions
        assert high_vol_count > 0, f'High-volume topic should have consumed messages, got {high_vol_count}'
        assert low_vol_count > 0, f'Low-volume topic should NOT be starved, got {low_vol_count}'
        
        # Key test: Fair representation despite volume difference
        if total_consumed > 0:
            fairness_ratio = low_vol_count / total_consumed
            assert fairness_ratio > 0.01, f'Low-volume topic got {fairness_ratio:.2%} - indicates starvation!'
        
        print(f'âœ… SUCCESS: Async polling prevented topic starvation!')
        print(f'   Low-volume topic maintained fair representation despite high-volume load')
        
        # Cleanup
        import shutil
        shutil.rmtree(test_output_dir)
        print(f'ğŸ§¹ Cleaned up test directory')
        "
      env:
        PYTHONPATH: /home/runner/work/bizon-core/bizon-core

    - name: Test starvation comparison (sync vs async)
      run: |
        echo "âš–ï¸  Testing sync vs async polling comparison..."
        poetry run python -c "
        import json
        import tempfile
        import os
        import shutil
        from pathlib import Path
        
        def run_bizon_test(polling_mode, test_name):
            '''Run bizon with specified polling mode'''
            
            test_output_dir = tempfile.mkdtemp(prefix=f'kafka_{polling_mode}_test_')
            print(f'ğŸ“ {test_name} output directory: {test_output_dir}')
            
            enable_async = (polling_mode == 'async')
            
            config_yaml = f'''
            name: ci_kafka_{polling_mode}_test
            source:
              name: kafka
              stream: topic
              sync_mode: stream
              topics:
                - name: async-test-high-volume
                  destination_id: high_volume
                - name: async-test-low-volume
                  destination_id: low_volume
              bootstrap_servers: localhost:9092
              group_id: ci-{polling_mode}-test-group
              batch_size: 25
              consumer_timeout: 1
              enable_async_polling: {str(enable_async).lower()}
              poll_interval_ms: 50
              max_poll_records: 50
              message_encoding: utf-8
              max_iterations: 5
              authentication:
                type: basic
                params:
                  username: test
                  password: test
                schema_registry_type: apicurio
                schema_registry_url: ''
                schema_registry_username: ''
                schema_registry_password: ''
            destination:
              name: file
              config:
                output_dir: {test_output_dir}
                record_schemas:
                  - destination_id: high_volume
                    record_schema:
                      - name: id
                        type: string
                        nullable: false
                      - name: type  
                        type: string
                        nullable: false
                  - destination_id: low_volume
                    record_schema:
                      - name: id
                        type: string
                        nullable: false
                      - name: type
                        type: string
                        nullable: false
            engine:
              runner:
                type: stream
              backend:
                type: sqlite
                config:
                  database_path: {os.path.join(test_output_dir, 'test.db')}
            '''
            
            # Write and run config
            config_file = os.path.join(test_output_dir, 'config.yml')
            with open(config_file, 'w') as f:
                f.write(config_yaml)
            
            os.environ['ENVIRONMENT'] = 'production'
            
            import yaml
            from bizon.engine.engine import RunnerFactory
            
            with open(config_file, 'r') as f:
                config_dict = yaml.safe_load(f)
            
            runner = RunnerFactory.create_from_config_dict(config_dict)
            runner.run()
            
            # Count results
            high_vol_file = os.path.join(test_output_dir, 'high_volume.json')
            low_vol_file = os.path.join(test_output_dir, 'low_volume.json')
            
            high_vol_count = 0
            low_vol_count = 0
            
            if os.path.exists(high_vol_file):
                with open(high_vol_file, 'r') as f:
                    high_vol_count = sum(1 for line in f if line.strip())
            
            if os.path.exists(low_vol_file):
                with open(low_vol_file, 'r') as f:
                    low_vol_count = sum(1 for line in f if line.strip())
            
            # Cleanup
            shutil.rmtree(test_output_dir)
            
            return high_vol_count, low_vol_count
        
        # Run both tests
        print('ğŸ”„ Running sync polling test...')
        sync_high, sync_low = run_bizon_test('sync', 'Sync Polling')
        
        print('ğŸ”„ Running async polling test...')  
        async_high, async_low = run_bizon_test('async', 'Async Polling')
        
        # Compare results
        print(f'')
        print(f'ğŸ“Š Polling Mode Comparison Results:')
        print(f'   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”')
        print(f'   â”‚ Polling Mode    â”‚ High Volume â”‚ Low Volume  â”‚')
        print(f'   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤')
        print(f'   â”‚ Sync (old)      â”‚ {sync_high:11d} â”‚ {sync_low:11d} â”‚')
        print(f'   â”‚ Async (new)     â”‚ {async_high:11d} â”‚ {async_low:11d} â”‚')
        print(f'   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜')
        
        # Analysis
        sync_total = sync_high + sync_low
        async_total = async_high + async_low
        
        if sync_total > 0:
            sync_low_pct = (sync_low / sync_total) * 100
        else:
            sync_low_pct = 0
            
        if async_total > 0:
            async_low_pct = (async_low / async_total) * 100
        else:
            async_low_pct = 0
        
        print(f'')
        print(f'ğŸ“ˆ Starvation Analysis:')
        print(f'   Sync polling  - Low volume: {sync_low_pct:.1f}%')
        print(f'   Async polling - Low volume: {async_low_pct:.1f}%')
        
        # Key assertions
        assert async_low > 0, f'Async polling should consume low-volume messages, got {async_low}'
        assert async_low_pct >= sync_low_pct, f'Async should be >= sync fairness: {async_low_pct:.1f}% vs {sync_low_pct:.1f}%'
        
        if sync_low == 0 and async_low > 0:
            print(f'ğŸ‰ MAJOR SUCCESS: Async polling prevented complete starvation!')
        elif async_low > sync_low:
            improvement = ((async_low - sync_low) / max(sync_low, 1)) * 100
            print(f'ğŸ‰ SUCCESS: Async polling improved low-volume consumption by {improvement:.0f}%!')
        else:
            print(f'âœ… SUCCESS: Async polling maintained fair consumption')
        
        print(f'âœ… Starvation prevention test passed!')
        "
      env:
        PYTHONPATH: /home/runner/work/bizon-core/bizon-core

    - name: Verify Redpanda consumer groups
      if: always()
      run: |
        echo "ğŸ‘¥ Checking Redpanda consumer groups created during test..."
        poetry run python -c "
        from confluent_kafka.admin import AdminClient
        
        admin_client = AdminClient({'bootstrap.servers': 'localhost:9092'})
        
        try:
            groups = admin_client.list_consumer_groups(timeout=10)
            print(f'ğŸ“‹ Consumer groups found: {len(groups)}')
            for group in groups:
                print(f'   - {group}')
        except Exception as e:
            print(f'â„¹ï¸  Could not list consumer groups: {e}')
        "

    - name: Cleanup test topics
      if: always()
      run: |
        echo "ğŸ§¹ Cleaning up test topics..."
        poetry run python -c "
        from confluent_kafka.admin import AdminClient
        
        admin_client = AdminClient({'bootstrap.servers': 'localhost:9092'})
        
        topics_to_delete = ['async-test-high-volume', 'async-test-low-volume', 'test-topic']
        
        try:
            futures = admin_client.delete_topics(topics_to_delete, timeout=10)
            for topic, future in futures.items():
                try:
                    future.result()
                    print(f'ğŸ—‘ï¸  Deleted topic: {topic}')
                except Exception as e:
                    print(f'â„¹ï¸  Could not delete topic {topic}: {e}')
        except Exception as e:
            print(f'â„¹ï¸  Cleanup completed with some issues: {e}')
        "

    - name: Stop Redpanda container
      if: always()
      run: |
        echo "ğŸ›‘ Stopping Redpanda container..."
        docker stop redpanda || true
        docker rm redpanda || true

    - name: Test Summary
      if: always()
      run: |
        echo "ğŸ¯ Kafka Async Polling E2E Test Summary"
        echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        echo "âœ… Redpanda cluster setup and connectivity"
        echo "âœ… Test data production (high/low volume)"
        echo "âœ… Async polling unit tests"  
        echo "âœ… Integration test with file destination"
        echo "âœ… Starvation prevention validation"
        echo "âœ… Sync vs async polling comparison"
        echo ""
        echo "ğŸš€ All tests passed! Async polling prevents topic starvation."