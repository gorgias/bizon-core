name: Kafka Async Polling E2E Tests

on:
  pull_request:
    paths:
      - 'bizon/connectors/sources/kafka/**'
      - 'tests/e2e/test_e2e_kafka_async_polling.py'
      - 'tests/connectors/sources/kafka/**'
      - '.github/workflows/kafka-e2e.yml'
  push:
    branches:
      - main
      - develop
    paths:
      - 'bizon/connectors/sources/kafka/**'
      - 'tests/e2e/test_e2e_kafka_async_polling.py'
      - 'tests/connectors/sources/kafka/**'
  workflow_dispatch: # Allow manual trigger

permissions:
  contents: read

jobs:
  kafka-e2e-test:
    name: Kafka Async Polling E2E Tests
    runs-on: ubuntu-latest
    timeout-minutes: 15


    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python 3.10
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Start Redpanda
      run: |
        echo "Starting Redpanda container..."
        docker run -d \
          --name redpanda \
          -p 9092:9092 \
          -p 9644:9644 \
          docker.redpanda.com/redpandadata/redpanda:latest \
          redpanda start \
          --node-id 0 \
          --mode dev-container \
          --kafka-addr internal://0.0.0.0:9092,external://0.0.0.0:19092 \
          --advertise-kafka-addr internal://redpanda:9092,external://localhost:9092 \
          --pandaproxy-addr internal://0.0.0.0:8082,external://0.0.0.0:18082 \
          --advertise-pandaproxy-addr internal://redpanda:8082,external://localhost:8082 \
          --schema-registry-addr internal://0.0.0.0:8081,external://0.0.0.0:18081 \
          --rpc-addr redpanda:33145 \
          --advertise-rpc-addr redpanda:33145 \
          --smp 1 \
          --memory 1G \
          --reserve-memory 0M \
          --overprovisioned \
          --set redpanda.empty_seed_starts_cluster=false \
          --set redpanda.auto_create_topics_enabled=true

    - name: Wait for Redpanda to be ready
      run: |
        echo "Waiting for Redpanda to be ready..."
        timeout 60s bash -c 'until docker exec redpanda rpk cluster info; do sleep 2; done'
        echo "Redpanda is ready!"

    - name: Install Poetry
      uses: snok/install-poetry@v1
      with:
        version: latest
        virtualenvs-create: true
        virtualenvs-in-project: true

    - name: Load cached venv
      id: cached-poetry-dependencies
      uses: actions/cache@v3
      with:
        path: .venv
        key: venv-${{ runner.os }}-${{ steps.setup-python.outputs.python-version }}-${{ hashFiles('**/poetry.lock') }}

    - name: Install dependencies
      if: steps.cached-poetry-dependencies.outputs.cache-hit != 'true'
      run: poetry install --with test --all-extras

    - name: Verify Redpanda connection
      run: |
        echo "Verifying Redpanda (Kafka-compatible) setup..."
        poetry run python -c "
        from confluent_kafka import Producer
        import time
        
        producer = Producer({'bootstrap.servers': 'localhost:9092'})
        producer.produce('test-topic', 'test-message')
        producer.flush()
        print('‚úÖ Redpanda connection verified!')
        "

    - name: Create test topics and produce data
      run: |
        poetry run python -c "
        import json
        import time
        from confluent_kafka import Producer
        from confluent_kafka.admin import AdminClient, NewTopic
        
        print('üéØ Setting up Redpanda test environment...')
        
        # Create topics
        admin_client = AdminClient({'bootstrap.servers': 'localhost:9092'})
        topics = [
            NewTopic('async-test-high-volume', num_partitions=3, replication_factor=1),
            NewTopic('async-test-low-volume', num_partitions=1, replication_factor=1)
        ]
        
        futures = admin_client.create_topics(topics)
        for topic_name, future in futures.items():
            try:
                future.result(timeout=10)
                print(f'‚úÖ Created topic: {topic_name}')
            except Exception as e:
                if 'already exists' in str(e).lower():
                    print(f'‚ÑπÔ∏è  Topic {topic_name} already exists')
                else:
                    print(f'‚ùå Failed to create topic {topic_name}: {e}')
                    raise
        
        # Produce test data
        producer = Producer({
            'bootstrap.servers': 'localhost:9092',
            'client.id': 'ci-test-producer'
        })
        
        print('üöÄ Producing test data to simulate starvation scenario...')
        
        # High-volume topic - simulate heavy load (200 messages)
        for i in range(200):
            message = {
                'id': f'high-vol-{i}',
                'type': 'high_volume',
                'data': f'High volume message {i}',
                'timestamp': int(time.time() * 1000),
                'batch': i // 20
            }
            
            producer.produce(
                'async-test-high-volume',
                key=f'high-vol-{i}',
                value=json.dumps(message),
                partition=i % 3
            )
            
            if i % 50 == 0:
                producer.flush()
        
        # Low-volume topic - simulate critical but infrequent messages (10 messages)
        for i in range(10):
            message = {
                'id': f'low-vol-{i}',
                'type': 'low_volume',
                'data': f'Critical message {i}',
                'priority': 'HIGH',
                'timestamp': int(time.time() * 1000),
                'sequence': i
            }
            
            producer.produce(
                'async-test-low-volume',
                key=f'low-vol-{i}',
                value=json.dumps(message),
                partition=0
            )
        
        producer.flush()
        print('üì¶ Test data produced successfully!')
        print('   - High-volume topic: 200 messages across 3 partitions')
        print('   - Low-volume topic: 10 critical messages in 1 partition')
        "

    - name: Run Kafka async polling unit tests
      run: |
        echo "üß™ Running async polling unit tests..."
        poetry run pytest tests/connectors/sources/kafka/test_async_polling.py -v --tb=short

    - name: Run Kafka async polling integration test
      run: |
        echo "üî¨ Running async polling integration test..."
        poetry run python -c "
        import json
        import tempfile
        import os
        from pathlib import Path
        
        # Create test output directory
        test_output_dir = tempfile.mkdtemp(prefix='kafka_async_test_')
        print(f'üìÅ Test output directory: {test_output_dir}')
        
        # Test configuration
        config_yaml = '''
        name: ci_kafka_async_polling_test
        source:
          name: kafka
          stream: topic
          sync_mode: stream
          topics:
            - name: async-test-high-volume
              destination_id: high_volume
            - name: async-test-low-volume
              destination_id: low_volume
          bootstrap_servers: localhost:9092
          group_id: ci-async-test-group
          batch_size: 30
          consumer_timeout: 2
          enable_async_polling: true
          poll_interval_ms: 50
          max_poll_records: 100
          partition_pause_threshold: 500
          message_encoding: utf-8
          max_iterations: 8
          authentication:
            type: basic
            params:
              username: test
              password: test
            schema_registry_type: apicurio
            schema_registry_url: ''
            schema_registry_username: ''
            schema_registry_password: ''
        destination:
          name: file
          config:
            output_dir: ''' + test_output_dir + '''
            record_schemas:
              - destination_id: high_volume
                record_schema:
                  - name: id
                    type: string
                    nullable: false
                  - name: type
                    type: string
                    nullable: false
                  - name: data
                    type: string
                    nullable: false
                  - name: timestamp
                    type: integer
                    nullable: false
              - destination_id: low_volume
                record_schema:
                  - name: id
                    type: string
                    nullable: false
                  - name: type
                    type: string
                    nullable: false
                  - name: data
                    type: string
                    nullable: false
                  - name: priority
                    type: string
                    nullable: false
                  - name: timestamp
                    type: integer
                    nullable: false
        engine:
          runner:
            type: stream
          backend:
            type: sqlite
            config:
              database_path: ''' + os.path.join(test_output_dir, 'test.db') + '''
        '''
        
        # Write config to file
        config_file = os.path.join(test_output_dir, 'config.yml')
        with open(config_file, 'w') as f:
            f.write(config_yaml)
        
        print(f'üìÑ Config written to: {config_file}')
        
        # Set environment for production mode (enables commits)
        os.environ['ENVIRONMENT'] = 'production'
        
        # Run bizon
        print('üöÄ Running bizon with async polling...')
        
        import yaml
        from bizon.engine.engine import RunnerFactory
        
        with open(config_file, 'r') as f:
            config_dict = yaml.safe_load(f)
        
        runner = RunnerFactory.create_from_config_dict(config_dict)
        result = runner.run()
        
        print(f'‚úÖ Bizon completed with status: {result}')
        
        # Analyze results
        print('üìä Analyzing consumption results...')
        
        high_vol_file = os.path.join(test_output_dir, 'high_volume.json')
        low_vol_file = os.path.join(test_output_dir, 'low_volume.json')
        
        high_vol_count = 0
        low_vol_count = 0
        
        if os.path.exists(high_vol_file):
            with open(high_vol_file, 'r') as f:
                high_vol_count = sum(1 for line in f if line.strip())
        
        if os.path.exists(low_vol_file):
            with open(low_vol_file, 'r') as f:
                low_vol_count = sum(1 for line in f if line.strip())
        
        total_consumed = high_vol_count + low_vol_count
        
        print(f'üìà Consumption Results:')
        print(f'   High-volume messages: {high_vol_count}')
        print(f'   Low-volume messages:  {low_vol_count}')
        print(f'   Total consumed:       {total_consumed}')
        
        if total_consumed > 0:
            high_vol_pct = (high_vol_count / total_consumed) * 100
            low_vol_pct = (low_vol_count / total_consumed) * 100
            
            print(f'üìä Fairness Analysis:')
            print(f'   High-volume: {high_vol_pct:.1f}%')
            print(f'   Low-volume:  {low_vol_pct:.1f}%')
        
        # Assertions
        assert high_vol_count > 0, f'High-volume topic should have consumed messages, got {high_vol_count}'
        assert low_vol_count > 0, f'Low-volume topic should NOT be starved, got {low_vol_count}'
        
        # Key test: Fair representation despite volume difference
        if total_consumed > 0:
            fairness_ratio = low_vol_count / total_consumed
            assert fairness_ratio > 0.01, f'Low-volume topic got {fairness_ratio:.2%} - indicates starvation!'
        
        print(f'‚úÖ SUCCESS: Async polling prevented topic starvation!')
        print(f'   Low-volume topic maintained fair representation despite high-volume load')
        
        # Cleanup
        import shutil
        shutil.rmtree(test_output_dir)
        print(f'üßπ Cleaned up test directory')
        "
      env:
        PYTHONPATH: /home/runner/work/bizon-core/bizon-core

    - name: Test starvation comparison (sync vs async)
      run: |
        echo "‚öñÔ∏è  Testing sync vs async polling comparison..."
        poetry run python -c "
        import json
        import tempfile
        import os
        import shutil
        from pathlib import Path
        
        def run_bizon_test(polling_mode, test_name):
            '''Run bizon with specified polling mode'''
            
            test_output_dir = tempfile.mkdtemp(prefix=f'kafka_{polling_mode}_test_')
            print(f'üìÅ {test_name} output directory: {test_output_dir}')
            
            enable_async = (polling_mode == 'async')
            
            config_yaml = f'''
            name: ci_kafka_{polling_mode}_test
            source:
              name: kafka
              stream: topic
              sync_mode: stream
              topics:
                - name: async-test-high-volume
                  destination_id: high_volume
                - name: async-test-low-volume
                  destination_id: low_volume
              bootstrap_servers: localhost:9092
              group_id: ci-{polling_mode}-test-group
              batch_size: 25
              consumer_timeout: 1
              enable_async_polling: {str(enable_async).lower()}
              poll_interval_ms: 50
              max_poll_records: 50
              message_encoding: utf-8
              max_iterations: 5
              authentication:
                type: basic
                params:
                  username: test
                  password: test
                schema_registry_type: apicurio
                schema_registry_url: ''
                schema_registry_username: ''
                schema_registry_password: ''
            destination:
              name: file
              config:
                output_dir: {test_output_dir}
                record_schemas:
                  - destination_id: high_volume
                    record_schema:
                      - name: id
                        type: string
                        nullable: false
                      - name: type  
                        type: string
                        nullable: false
                  - destination_id: low_volume
                    record_schema:
                      - name: id
                        type: string
                        nullable: false
                      - name: type
                        type: string
                        nullable: false
            engine:
              runner:
                type: stream
              backend:
                type: sqlite
                config:
                  database_path: {os.path.join(test_output_dir, 'test.db')}
            '''
            
            # Write and run config
            config_file = os.path.join(test_output_dir, 'config.yml')
            with open(config_file, 'w') as f:
                f.write(config_yaml)
            
            os.environ['ENVIRONMENT'] = 'production'
            
            import yaml
            from bizon.engine.engine import RunnerFactory
            
            with open(config_file, 'r') as f:
                config_dict = yaml.safe_load(f)
            
            runner = RunnerFactory.create_from_config_dict(config_dict)
            runner.run()
            
            # Count results
            high_vol_file = os.path.join(test_output_dir, 'high_volume.json')
            low_vol_file = os.path.join(test_output_dir, 'low_volume.json')
            
            high_vol_count = 0
            low_vol_count = 0
            
            if os.path.exists(high_vol_file):
                with open(high_vol_file, 'r') as f:
                    high_vol_count = sum(1 for line in f if line.strip())
            
            if os.path.exists(low_vol_file):
                with open(low_vol_file, 'r') as f:
                    low_vol_count = sum(1 for line in f if line.strip())
            
            # Cleanup
            shutil.rmtree(test_output_dir)
            
            return high_vol_count, low_vol_count
        
        # Run both tests
        print('üîÑ Running sync polling test...')
        sync_high, sync_low = run_bizon_test('sync', 'Sync Polling')
        
        print('üîÑ Running async polling test...')  
        async_high, async_low = run_bizon_test('async', 'Async Polling')
        
        # Compare results
        print(f'')
        print(f'üìä Polling Mode Comparison Results:')
        print(f'   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê')
        print(f'   ‚îÇ Polling Mode    ‚îÇ High Volume ‚îÇ Low Volume  ‚îÇ')
        print(f'   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§')
        print(f'   ‚îÇ Sync (old)      ‚îÇ {sync_high:11d} ‚îÇ {sync_low:11d} ‚îÇ')
        print(f'   ‚îÇ Async (new)     ‚îÇ {async_high:11d} ‚îÇ {async_low:11d} ‚îÇ')
        print(f'   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò')
        
        # Analysis
        sync_total = sync_high + sync_low
        async_total = async_high + async_low
        
        if sync_total > 0:
            sync_low_pct = (sync_low / sync_total) * 100
        else:
            sync_low_pct = 0
            
        if async_total > 0:
            async_low_pct = (async_low / async_total) * 100
        else:
            async_low_pct = 0
        
        print(f'')
        print(f'üìà Starvation Analysis:')
        print(f'   Sync polling  - Low volume: {sync_low_pct:.1f}%')
        print(f'   Async polling - Low volume: {async_low_pct:.1f}%')
        
        # Key assertions
        assert async_low > 0, f'Async polling should consume low-volume messages, got {async_low}'
        assert async_low_pct >= sync_low_pct, f'Async should be >= sync fairness: {async_low_pct:.1f}% vs {sync_low_pct:.1f}%'
        
        if sync_low == 0 and async_low > 0:
            print(f'üéâ MAJOR SUCCESS: Async polling prevented complete starvation!')
        elif async_low > sync_low:
            improvement = ((async_low - sync_low) / max(sync_low, 1)) * 100
            print(f'üéâ SUCCESS: Async polling improved low-volume consumption by {improvement:.0f}%!')
        else:
            print(f'‚úÖ SUCCESS: Async polling maintained fair consumption')
        
        print(f'‚úÖ Starvation prevention test passed!')
        "
      env:
        PYTHONPATH: /home/runner/work/bizon-core/bizon-core

    - name: Verify Redpanda consumer groups
      if: always()
      run: |
        echo "üë• Checking Redpanda consumer groups created during test..."
        poetry run python -c "
        from confluent_kafka.admin import AdminClient
        
        admin_client = AdminClient({'bootstrap.servers': 'localhost:9092'})
        
        try:
            groups = admin_client.list_consumer_groups(timeout=10)
            print(f'üìã Consumer groups found: {len(groups)}')
            for group in groups:
                print(f'   - {group}')
        except Exception as e:
            print(f'‚ÑπÔ∏è  Could not list consumer groups: {e}')
        "

    - name: Cleanup test topics
      if: always()
      run: |
        echo "üßπ Cleaning up test topics..."
        poetry run python -c "
        from confluent_kafka.admin import AdminClient
        
        admin_client = AdminClient({'bootstrap.servers': 'localhost:9092'})
        
        topics_to_delete = ['async-test-high-volume', 'async-test-low-volume', 'test-topic']
        
        try:
            futures = admin_client.delete_topics(topics_to_delete, timeout=10)
            for topic, future in futures.items():
                try:
                    future.result()
                    print(f'üóëÔ∏è  Deleted topic: {topic}')
                except Exception as e:
                    print(f'‚ÑπÔ∏è  Could not delete topic {topic}: {e}')
        except Exception as e:
            print(f'‚ÑπÔ∏è  Cleanup completed with some issues: {e}')
        "

    - name: Stop Redpanda container
      if: always()
      run: |
        echo "üõë Stopping Redpanda container..."
        docker stop redpanda || true
        docker rm redpanda || true

    - name: Test Summary
      if: always()
      run: |
        echo "üéØ Kafka Async Polling E2E Test Summary"
        echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
        echo "‚úÖ Redpanda cluster setup and connectivity"
        echo "‚úÖ Test data production (high/low volume)"
        echo "‚úÖ Async polling unit tests"  
        echo "‚úÖ Integration test with file destination"
        echo "‚úÖ Starvation prevention validation"
        echo "‚úÖ Sync vs async polling comparison"
        echo ""
        echo "üöÄ All tests passed! Async polling prevents topic starvation."